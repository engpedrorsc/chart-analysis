{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598491461359",
   "display_name": "Python 3.7.7 64-bit ('Trade': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Notebook dedicado à implementação e teste da AlexNet\n",
    "https://www.youtube.com/watch?v=8GheVe2UmUM\n",
    "./references/ImageNet Classification with Deep ConvolutionalNeural Networks.pdf\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import glob\n",
    "import shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class AssetNotFoundError(OSError):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Functions'''\n",
    "\n",
    "# Função para exibir uma amostra das imagens que serão usadas\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(25,25))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    '''\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    '''\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Parâmetros\n",
    "'''\n",
    "\n",
    "steps = ['train', 'valid', 'test']\n",
    "asset = 'VALE3'\n",
    "classes = ['long', 'short', 'wait']\n",
    "samples_sizes = [1150, 250, 245]\n",
    "\n",
    "data_path = Path(f'./generated_data/{asset}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indicator = ' <- Insuficient images'\n",
    "print('class: available / needed\\n')\n",
    "for classification in classes:\n",
    "    search_str = str(data_path/f'*{classification}*')\n",
    "    search_res = glob.glob(search_str)\n",
    "    warning = ''\n",
    "    if len(search_res) < sum(samples_sizes):\n",
    "        warning = indicator\n",
    "    print(f'{classification}: {str(len(search_res))} / {sum(samples_sizes)}{warning}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Idendificação e configuração da GPU\n",
    "'''\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print('Num GPUs available: ', len(physical_devices))\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Cria as pastas de treinamento, validação e teste com as classes indicadas caso ainda não existam\n",
    "'''\n",
    "\n",
    "if not Path.is_dir(data_path):\n",
    "    raise AssetNotFoundError('Asset folder not found.')\n",
    "\n",
    "for step in steps:\n",
    "    step_path = Path(data_path/step)\n",
    "    step_path.mkdir(exist_ok=True)\n",
    "    for classification in classes:\n",
    "        classification_path = Path(step_path/classification)\n",
    "        classification_path.mkdir(exist_ok=True)\n",
    "print('Folder structure created.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Seleciona aleatoriamente os gráficos que serão usados nas etapas de treinamento, velidação e teste e os move para as pastas correspondentes\n",
    "As amostras são colhidas de forma equilibrada\n",
    "'''\n",
    "\n",
    "for i in range(0,len(steps)):\n",
    "    step_path = Path(data_path/steps[i])\n",
    "    for classification in classes:\n",
    "        classification_path = Path(step_path/classification)\n",
    "        search_str = str(data_path/f'*{classification}*')\n",
    "        for chart in random.sample(glob.glob(search_str), samples_sizes[i]):\n",
    "            shutil.move(chart, classification_path)\n",
    "print('Images moved to destination folders.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rescale = 1/255\n",
    "zoom_range = 0\n",
    "target_size = (300,300)\n",
    "batch_size = 100\n",
    "class_mode = 'categorical'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=rescale, zoom_range=zoom_range)\n",
    "train_batches = train_datagen.flow_from_directory(f'{data_path}/train',\n",
    "                                              target_size=target_size,\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode=class_mode)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=rescale, zoom_range=zoom_range)\n",
    "test_batches = train_datagen.flow_from_directory(f'{data_path}/test',\n",
    "                                              target_size=target_size,\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode=class_mode)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=rescale, zoom_range=zoom_range)\n",
    "valid_batches = train_datagen.flow_from_directory(f'{data_path}/valid',\n",
    "                                              target_size=target_size,\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode=class_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs, labels = next(train_batches)\n",
    "plotImages(imgs)\n",
    "print(labels[0:9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AlexNet\n",
    "# Conv2D\n",
    "# MaxPool2D\n",
    "# BatchNormalization\n",
    "# Flatten\n",
    "# Dense\n",
    "# Dropout\n",
    "model = Sequential([\n",
    "    Conv2D(filters=4, kernel_size=5, strides=2, padding='same', activation='relu', input_shape=(target_size[0], target_size[1], 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=4, strides=2, padding='same'),\n",
    "    # Conv2D(filters=8, kernel_size=7, strides=4, padding='same', activation='relu'),\n",
    "    # BatchNormalization(),\n",
    "    # MaxPool2D(pool_size=4, strides=2, padding='same'),\n",
    "    # Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "    # BatchNormalization(),\n",
    "    # Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "    # BatchNormalization(),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=2, strides=1, padding='same'),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(200, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=categorical_crossentropy, optimizer='adam', metrics='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(x=train_batches, validation_data=valid_batches, epochs=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_imgs, test_labels = next(test_batches)\n",
    "plotImages(test_imgs)\n",
    "print(test_labels[0:9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=test_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=-1))\n",
    "cm_plot_labels = ['long', 'short', 'wait']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}